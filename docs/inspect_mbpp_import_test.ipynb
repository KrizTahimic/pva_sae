{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Import Pre-Loading Test Results Inspection (Temperature 0.0 ONLY)\n\n‚ö†Ô∏è **CRITICAL**: This notebook analyzes TEMPERATURE 0.0 data only for deterministic generation.\n\nThis notebook inspects the MBPP import test results to verify:\n- Test ran correctly with 55 imports pre-loaded at temperature 0.0\n- Pass rate comparison with baseline (both at temp=0.0)\n- Generated code samples\n- Investigation of why imports had minimal impact\n- **Root cause of 13 changed problems** (missing seed initialization)"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pandas display options set\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Set pandas display options to show FULL content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ Pandas display options set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "IMPORT PRE-LOADING TEST RESULTS\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Loaded test results: 388 records\n",
      "‚úÖ Loaded metadata\n"
     ]
    }
   ],
   "source": [
    "# Load test results (with imports)\n",
    "test_dir = Path(\"data/test_imports/20251121_124838\")\n",
    "test_file = test_dir / \"dataset_temp_0_0_with_imports.parquet\"\n",
    "metadata_file = test_dir / \"metadata.json\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"IMPORT PRE-LOADING TEST RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if test_file.exists():\n",
    "    df_test = pd.read_parquet(test_file)\n",
    "    print(f\"\\n‚úÖ Loaded test results: {len(df_test)} records\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Test file not found: {test_file}\")\n",
    "\n",
    "if metadata_file.exists():\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"‚úÖ Loaded metadata\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Metadata not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Baseline Results (Phase 3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded baseline results: 388 records\n",
      "‚úÖ Loaded baseline metadata\n"
     ]
    }
   ],
   "source": [
    "# Load baseline (without imports)\n",
    "baseline_file = Path(\"data/phase3_5/dataset_temp_0_0.parquet\")\n",
    "baseline_metadata = Path(\"data/phase3_5/metadata.json\")\n",
    "\n",
    "if baseline_file.exists():\n",
    "    df_baseline = pd.read_parquet(baseline_file)\n",
    "    print(f\"‚úÖ Loaded baseline results: {len(df_baseline)} records\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Baseline file not found: {baseline_file}\")\n",
    "    df_baseline = None\n",
    "\n",
    "if baseline_metadata.exists():\n",
    "    with open(baseline_metadata, 'r') as f:\n",
    "        baseline_meta = json.load(f)\n",
    "    print(f\"‚úÖ Loaded baseline metadata\")\n",
    "else:\n",
    "    baseline_meta = None"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 2.5. Validate Temperature 0.0 Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"=\" * 80)\nprint(\"VALIDATING TEMPERATURE 0.0 DATA\")\nprint(\"=\" * 80)\n\n# Validate test data\nif 'temperature' in df_test.columns:\n    if not (df_test['temperature'] == 0.0).all():\n        raise ValueError(f\"Test data must be temperature 0.0 only! Found: {df_test['temperature'].unique()}\")\n    print(f\"\\n‚úÖ Validated: All test data is temperature 0.0\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  Warning: No temperature column in test data (assumed 0.0 from filename)\")\n\n# Validate baseline data\nif df_baseline is not None:\n    if 'temperature' in df_baseline.columns:\n        if not (df_baseline['temperature'] == 0.0).all():\n            raise ValueError(f\"Baseline data must be temperature 0.0 only! Found: {df_baseline['temperature'].unique()}\")\n        print(f\"‚úÖ Validated: All baseline data is temperature 0.0\")\n    else:\n        print(f\"‚ö†Ô∏è  Warning: No temperature column in baseline data (assumed 0.0 from filename)\")\n\nprint(f\"\\nüí° Why Temperature 0.0 Matters:\")\nprint(f\"   - Ensures deterministic code generation (same prompt ‚Üí same code)\")\nprint(f\"   - Enables fair comparison between baseline and test\")\nprint(f\"   - Requires proper seed initialization (torch.manual_seed, etc.)\")\nprint(f\"\\nüìå Note: Without seed initialization, even temp=0.0 can produce variation\")\nprint(f\"   This explains the 13 changed problems between runs!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metadata Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "METADATA COMPARISON\n",
      "================================================================================\n",
      "\n",
      "üìÑ Test Metadata:\n",
      "{\n",
      "  \"creation_timestamp\": \"2025-11-21T13:20:36.195461\",\n",
      "  \"test_description\": \"MBPP with 55 standard library imports pre-loaded\",\n",
      "  \"imports_preloaded\": 55,\n",
      "  \"dataset_range\": \"0-387\",\n",
      "  \"n_problems_tested\": 388,\n",
      "  \"n_passed\": 117,\n",
      "  \"n_failed\": 271,\n",
      "  \"pass_rate_percent\": 30.15,\n",
      "  \"avg_generation_time\": 4.923806269758756,\n",
      "  \"best_layers\": {\n",
      "    \"correct\": 16,\n",
      "    \"incorrect\": 19,\n",
      "    \"correct_feature_idx\": 14439,\n",
      "    \"incorrect_feature_idx\": 5441\n",
      "  },\n",
      "  \"imports\": [\n",
      "    \"from __future__ import annotations\",\n",
      "    \"from __future__ import print_function\",\n",
      "    \"import math\",\n",
      "    \"import re\",\n",
      "    \"import collections\",\n",
      "    \"import random\",\n",
      "    \"import sys\",\n",
      "    \"import itertools\",\n",
      "    \"import functools\",\n",
      "    \"import heapq\",\n",
      "    \"import string\",\n",
      "    \"import operator\",\n",
      "    \"import time\",\n",
      "    \"import copy\",\n",
      "    \"import datetime\",\n",
      "    \"import csv\",\n",
      "    \"import os\",\n",
      "    \"from collections import Counter\",\n",
      "    \"from collections import defaultdict\",\n",
      "    \"from collections import namedtuple\",\n",
      "    \"from collections import deque\",\n",
      "    \"from collections import OrderedDict\",\n",
      "    \"from typing import List\",\n",
      "    \"from typing import Tuple\",\n",
      "    \"from typing import Optional\",\n",
      "    \"from typing import Callable\",\n",
      "    \"from typing import Union\",\n",
      "    \"from functools import reduce\",\n",
      "    \"from functools import lru_cache\",\n",
      "    \"from itertools import combinations\",\n",
      "    \"from itertools import permutations\",\n",
      "    \"from itertools import chain\",\n",
      "    \"from itertools import compress\",\n",
      "    \"from itertools import filterfalse\",\n",
      "    \"from math import sqrt\",\n",
      "    \"from math import ceil\",\n",
      "    \"from math import factorial\",\n",
      "    \"from math import gcd\",\n",
      "    \"from math import hypot\",\n",
      "    \"from bisect import bisect_left\",\n",
      "    \"from bisect import bisect\",\n",
      "    \"from bisect import bisect_right\",\n",
      "    \"from copy import deepcopy\",\n",
      "    \"from operator import itemgetter\",\n",
      "    \"from operator import mul\",\n",
      "    \"from string import ascii_lowercase\",\n",
      "    \"from string import whitespace\",\n",
      "    \"from re import findall\",\n",
      "    \"from re import match\",\n",
      "    \"from re import compile\",\n",
      "    \"from datetime import date\",\n",
      "    \"from random import randint\",\n",
      "    \"from random import randrange\",\n",
      "    \"from sys import maxsize\",\n",
      "    \"from heapq import heappush, heappop\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "üìÑ Baseline Metadata (temp 0.0):\n",
      "{\n",
      "  \"n_correct\": 116,\n",
      "  \"n_incorrect\": 272,\n",
      "  \"pass_rate\": 0.29896907216494845,\n",
      "  \"avg_generation_time\": 10.921113641606164\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"METADATA COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìÑ Test Metadata:\")\n",
    "print(json.dumps(metadata, indent=2))\n",
    "\n",
    "if baseline_meta:\n",
    "    print(\"\\nüìÑ Baseline Metadata (temp 0.0):\")\n",
    "    baseline_stats = baseline_meta.get('temperature_stats', {}).get('0.0', {})\n",
    "    print(json.dumps(baseline_stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pass Rate Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PASS RATE COMPARISON\n",
      "================================================================================\n",
      "\n",
      "üìä WITH IMPORTS (Test):\n",
      "  Passed: 117/388\n",
      "  Failed: 271/388\n",
      "  Pass rate: 30.15%\n",
      "\n",
      "üìä WITHOUT IMPORTS (Baseline):\n",
      "  Passed: 116/388\n",
      "  Failed: 272/388\n",
      "  Pass rate: 29.90%\n",
      "\n",
      "üìà DIFFERENCE:\n",
      "  Additional passes: +1\n",
      "  Rate difference: +0.25%\n",
      "  Relative improvement: +0.86%\n",
      "\n",
      "üí° CONCLUSION:\n",
      "  ‚ö†Ô∏è  NEGLIGIBLE IMPACT - Only 1 problem(s) changed\n",
      "  Pre-loading imports does NOT significantly improve pass rate\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PASS RATE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test results\n",
    "test_passed = metadata['n_passed']\n",
    "test_failed = metadata['n_failed']\n",
    "test_total = metadata['n_problems_tested']\n",
    "test_rate = metadata['pass_rate_percent']\n",
    "\n",
    "print(f\"\\nüìä WITH IMPORTS (Test):\")\n",
    "print(f\"  Passed: {test_passed}/{test_total}\")\n",
    "print(f\"  Failed: {test_failed}/{test_total}\")\n",
    "print(f\"  Pass rate: {test_rate:.2f}%\")\n",
    "\n",
    "if baseline_meta:\n",
    "    baseline_stats = baseline_meta['temperature_stats']['0.0']\n",
    "    baseline_passed = baseline_stats['n_correct']\n",
    "    baseline_failed = baseline_stats['n_incorrect']\n",
    "    baseline_total = baseline_passed + baseline_failed\n",
    "    baseline_rate = baseline_stats['pass_rate'] * 100\n",
    "    \n",
    "    print(f\"\\nüìä WITHOUT IMPORTS (Baseline):\")\n",
    "    print(f\"  Passed: {baseline_passed}/{baseline_total}\")\n",
    "    print(f\"  Failed: {baseline_failed}/{baseline_total}\")\n",
    "    print(f\"  Pass rate: {baseline_rate:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüìà DIFFERENCE:\")\n",
    "    diff_passed = test_passed - baseline_passed\n",
    "    diff_rate = test_rate - baseline_rate\n",
    "    print(f\"  Additional passes: {diff_passed:+d}\")\n",
    "    print(f\"  Rate difference: {diff_rate:+.2f}%\")\n",
    "    \n",
    "    if diff_passed > 0:\n",
    "        improvement = (diff_passed / baseline_passed) * 100\n",
    "        print(f\"  Relative improvement: {improvement:+.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüí° CONCLUSION:\")\n",
    "    if abs(diff_passed) <= 2:\n",
    "        print(f\"  ‚ö†Ô∏è  NEGLIGIBLE IMPACT - Only {diff_passed} problem(s) changed\")\n",
    "        print(f\"  Pre-loading imports does NOT significantly improve pass rate\")\n",
    "    elif diff_passed > 5:\n",
    "        print(f\"  ‚úÖ POSITIVE IMPACT - {diff_passed} additional problems passed\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  MINIMAL IMPACT - Only {diff_passed} problems improved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find Which Problem(s) Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "IDENTIFYING CHANGED PROBLEMS\n",
      "================================================================================\n",
      "\n",
      "üîç Found 13 problem(s) with different results:\n",
      "\n",
      "  Task 199: NOW PASSES\n",
      "    Baseline: FAIL\n",
      "    With imports: PASS\n",
      "\n",
      "  Task 319: NOW FAILS\n",
      "    Baseline: PASS\n",
      "    With imports: FAIL\n",
      "\n",
      "  Task 455: NOW PASSES\n",
      "    Baseline: FAIL\n",
      "    With imports: PASS\n",
      "\n",
      "  Task 460: NOW PASSES\n",
      "    Baseline: FAIL\n",
      "    With imports: PASS\n",
      "\n",
      "  Task 555: NOW FAILS\n",
      "    Baseline: PASS\n",
      "    With imports: FAIL\n",
      "\n",
      "  Task 593: NOW PASSES\n",
      "    Baseline: FAIL\n",
      "    With imports: PASS\n",
      "\n",
      "  Task 688: NOW PASSES\n",
      "    Baseline: FAIL\n",
      "    With imports: PASS\n",
      "\n",
      "  Task 693: NOW PASSES\n",
      "    Baseline: FAIL\n",
      "    With imports: PASS\n",
      "\n",
      "  Task 711: NOW FAILS\n",
      "    Baseline: PASS\n",
      "    With imports: FAIL\n",
      "\n",
      "  Task 806: NOW FAILS\n",
      "    Baseline: PASS\n",
      "    With imports: FAIL\n",
      "\n",
      "  Task 866: NOW FAILS\n",
      "    Baseline: PASS\n",
      "    With imports: FAIL\n",
      "\n",
      "  Task 880: NOW FAILS\n",
      "    Baseline: PASS\n",
      "    With imports: FAIL\n",
      "\n",
      "  Task 919: NOW PASSES\n",
      "    Baseline: FAIL\n",
      "    With imports: PASS\n",
      "\n",
      "üìù Storing changed problems for detailed inspection...\n"
     ]
    }
   ],
   "source": [
    "if df_baseline is not None:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"IDENTIFYING CHANGED PROBLEMS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Merge on task_id\n",
    "    comparison = df_test[['task_id', 'test_passed', 'generated_code']].merge(\n",
    "        df_baseline[['task_id', 'test_passed', 'generated_code']],\n",
    "        on='task_id',\n",
    "        suffixes=('_test', '_baseline')\n",
    "    )\n",
    "    \n",
    "    # Find where results differ\n",
    "    changed = comparison[comparison['test_passed_test'] != comparison['test_passed_baseline']]\n",
    "    \n",
    "    print(f\"\\nüîç Found {len(changed)} problem(s) with different results:\")\n",
    "    \n",
    "    if len(changed) > 0:\n",
    "        for idx, row in changed.iterrows():\n",
    "            status = \"NOW PASSES\" if row['test_passed_test'] else \"NOW FAILS\"\n",
    "            print(f\"\\n  Task {row['task_id']}: {status}\")\n",
    "            print(f\"    Baseline: {'PASS' if row['test_passed_baseline'] else 'FAIL'}\")\n",
    "            print(f\"    With imports: {'PASS' if row['test_passed_test'] else 'FAIL'}\")\n",
    "        \n",
    "        print(f\"\\nüìù Storing changed problems for detailed inspection...\")\n",
    "        changed_tasks = changed['task_id'].tolist()\n",
    "    else:\n",
    "        print(\"\\n  No problems changed status (identical results!)\")\n",
    "        changed_tasks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. CRITICAL: Investigate \"NOW FAILS\" Cases\n",
    "\n",
    "**Why are some problems FAILING with imports?** This should be impossible - imports should only HELP, never HURT!\n",
    "\n",
    "Let's investigate whether:\n",
    "1. Codes are IDENTICAL (import conflict/bug)\n",
    "2. Codes are DIFFERENT (random temperature variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INVESTIGATION: WHY DO PROBLEMS FAIL WITH IMPORTS?\n",
      "================================================================================\n",
      "\n",
      "üö® Found 6 problems that NOW FAIL with imports:\n",
      "   (This should be IMPOSSIBLE - imports should only help!)\n",
      "\n",
      "================================================================================\n",
      "Task 319: BASELINE PASSED ‚Üí TEST FAILED\n",
      "================================================================================\n",
      "\n",
      "‚úÖ CODES ARE DIFFERENT - Random temperature variation (not imports fault)\n",
      "\n",
      "Baseline Code (PASSED):\n",
      "--------------------------------------------------------------------------------\n",
      "def find_long_word(string):\n",
      "    return [word for word in string.split() if len(word) == 5]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test Code (FAILED):\n",
      "--------------------------------------------------------------------------------\n",
      "def find_long_word(string):\n",
      "    return [word for word in string.split() if len(word) >= 5]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Task 555: BASELINE PASSED ‚Üí TEST FAILED\n",
      "================================================================================\n",
      "\n",
      "‚úÖ CODES ARE DIFFERENT - Random temperature variation (not imports fault)\n",
      "\n",
      "Baseline Code (PASSED):\n",
      "--------------------------------------------------------------------------------\n",
      "def difference(n):\n",
      "    sum_of_cubes = 0\n",
      "    sum_of_natural_numbers = 0\n",
      "    for i in range(1, n+1):\n",
      "        sum_of_cubes += i**3\n",
      "        sum_of_natural_numbers += i\n",
      "    return sum_of_cubes - sum_of_natural_numbers\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test Code (FAILED):\n",
      "--------------------------------------------------------------------------------\n",
      "def difference(n):\n",
      "    return sum(range(1, n + 1)) ** 3 - sum(range(1, n + 1))\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Task 711: BASELINE PASSED ‚Üí TEST FAILED\n",
      "================================================================================\n",
      "\n",
      "‚úÖ CODES ARE DIFFERENT - Random temperature variation (not imports fault)\n",
      "\n",
      "Baseline Code (PASSED):\n",
      "--------------------------------------------------------------------------------\n",
      "def product_Equal(num):\n",
      "    if num < 0:\n",
      "        return False\n",
      "    else:\n",
      "        num = abs(num)\n",
      "        num_list = list(str(num))\n",
      "        even_product = 1\n",
      "        odd_product = 1\n",
      "        for i in range(len(num_list)):\n",
      "            if i % 2 == 0:\n",
      "                even_product *= int(num_list[i])\n",
      "        \n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test Code (FAILED):\n",
      "--------------------------------------------------------------------------------\n",
      "def product_Equal(number):\n",
      "    if number < 0:\n",
      "        return False\n",
      "    else:\n",
      "        product = 1\n",
      "        for i in range(1, len(str(number)) + 1):\n",
      "            if i % 2 == 0:\n",
      "                product *= int(str(number)[i - 1])\n",
      "            else:\n",
      "                product *= int(str(number)[i - 1]) * int(s\n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Task 806: BASELINE PASSED ‚Üí TEST FAILED\n",
      "================================================================================\n",
      "\n",
      "‚úÖ CODES ARE DIFFERENT - Random temperature variation (not imports fault)\n",
      "\n",
      "Baseline Code (PASSED):\n",
      "--------------------------------------------------------------------------------\n",
      "def max_run_uppercase(s):\n",
      "    max_run = 0\n",
      "    for i in range(len(s)):\n",
      "        run = 1\n",
      "        while i + run < len(s) and s[i].isupper() and s[i + run].isupper():\n",
      "            run += 1\n",
      "        if run > max_run:\n",
      "            max_run = run\n",
      "    return max_run\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test Code (FAILED):\n",
      "--------------------------------------------------------------------------------\n",
      "def max_run_uppercase(s):\n",
      "    max_run = 0\n",
      "    for i in range(len(s)):\n",
      "        if s[i].isupper():\n",
      "            max_run = max(max_run, len(s[i:]))\n",
      "    return max_run\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Task 866: BASELINE PASSED ‚Üí TEST FAILED\n",
      "================================================================================\n",
      "\n",
      "‚úÖ CODES ARE DIFFERENT - Random temperature variation (not imports fault)\n",
      "\n",
      "Baseline Code (PASSED):\n",
      "--------------------------------------------------------------------------------\n",
      "def check_monthnumb(month):\n",
      "    if month == \"January\" or month == \"March\" or month == \"May\" or month == \"July\" or month == \"August\" or month == \"October\" or month == \"December\":\n",
      "        return True\n",
      "    else:\n",
      "        return False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test Code (FAILED):\n",
      "--------------------------------------------------------------------------------\n",
      "def check_monthnumb(month):\n",
      "    if month in [\"January\", \"March\", \"May\", \"July\", \"August\", \"October\", \"December\"]:\n",
      "        return True\n",
      "    elif month in [\"April\", \"June\", \"September\", \"November\"]:\n",
      "        return False\n",
      "    else:\n",
      "        return \"Invalid month name\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Task 880: BASELINE PASSED ‚Üí TEST FAILED\n",
      "================================================================================\n",
      "\n",
      "‚úÖ CODES ARE DIFFERENT - Random temperature variation (not imports fault)\n",
      "\n",
      "Baseline Code (PASSED):\n",
      "--------------------------------------------------------------------------------\n",
      "def Check_Solution(a,b,c):\n",
      "    if a == 0:\n",
      "        if b == 0:\n",
      "            return \"No solutions\"\n",
      "        else:\n",
      "            return \"1 solution\"\n",
      "    else:\n",
      "        d = b**2 - 4*a*c\n",
      "        if d < 0:\n",
      "            return \"No solutions\"\n",
      "        elif d == 0:\n",
      "            return \"1 solution\"\n",
      "        else:\n",
      "     \n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test Code (FAILED):\n",
      "--------------------------------------------------------------------------------\n",
      "def Check_Solution(a,b,c):\n",
      "    if a == 0:\n",
      "        if b == 0:\n",
      "            return \"No solutions\"\n",
      "        else:\n",
      "            return \"1 solution\"\n",
      "    else:\n",
      "        return \"2 solutions\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF 'NOW FAILS' CASES\n",
      "================================================================================\n",
      "\n",
      "Total 'NOW FAILS': 6\n",
      "  - IDENTICAL code: 0 (import conflict/bug)\n",
      "  - DIFFERENT code: 6 (random variation)\n",
      "\n",
      "‚úÖ All 'NOW FAILS' are due to DIFFERENT code\n",
      "   This is normal temperature variation - NOT caused by imports\n",
      "   Imports are NOT causing harm!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"INVESTIGATION: WHY DO PROBLEMS FAIL WITH IMPORTS?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Filter for \"NOW FAILS\" cases\n",
    "if 'changed' in locals():\n",
    "    now_fails = changed[~changed['test_passed_test'] & changed['test_passed_baseline']]\n",
    "    \n",
    "    print(f\"\\nüö® Found {len(now_fails)} problems that NOW FAIL with imports:\")\n",
    "    print(f\"   (This should be IMPOSSIBLE - imports should only help!)\\n\")\n",
    "    \n",
    "    identical_count = 0\n",
    "    different_count = 0\n",
    "    \n",
    "    for idx, row in now_fails.iterrows():\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Task {row['task_id']}: BASELINE PASSED ‚Üí TEST FAILED\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Check if codes are identical\n",
    "        codes_identical = (row['generated_code_baseline'] == row['generated_code_test'])\n",
    "        \n",
    "        if codes_identical:\n",
    "            identical_count += 1\n",
    "            print(f\"\\n‚ö†Ô∏è  CODES ARE IDENTICAL - This suggests import conflict or evaluation bug!\")\n",
    "            print(f\"\\nGenerated Code (same in both runs):\")\n",
    "            print(\"-\" * 80)\n",
    "            print(row['generated_code_baseline'][:500])\n",
    "            if len(row['generated_code_baseline']) > 500:\n",
    "                print(\"...\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            # Check if this code uses any libraries\n",
    "            baseline_row = df_baseline[df_baseline['task_id'] == row['task_id']].iloc[0]\n",
    "            if 'library_usage' in df_baseline.columns:\n",
    "                lib_usage = baseline_row.get('library_usage', {})\n",
    "                print(f\"\\nLibraries Used: {lib_usage if lib_usage else 'None (pure Python)'}\")\n",
    "        else:\n",
    "            different_count += 1\n",
    "            print(f\"\\n‚úÖ CODES ARE DIFFERENT - Random temperature variation (not imports fault)\")\n",
    "            print(f\"\\nBaseline Code (PASSED):\")\n",
    "            print(\"-\" * 80)\n",
    "            print(row['generated_code_baseline'][:300])\n",
    "            if len(row['generated_code_baseline']) > 300:\n",
    "                print(\"...\")\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"\\nTest Code (FAILED):\")\n",
    "            print(\"-\" * 80)\n",
    "            print(row['generated_code_test'][:300])\n",
    "            if len(row['generated_code_test']) > 300:\n",
    "                print(\"...\")\n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SUMMARY OF 'NOW FAILS' CASES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nTotal 'NOW FAILS': {len(now_fails)}\")\n",
    "    print(f\"  - IDENTICAL code: {identical_count} (import conflict/bug)\")\n",
    "    print(f\"  - DIFFERENT code: {different_count} (random variation)\")\n",
    "    \n",
    "    if identical_count > 0:\n",
    "        print(f\"\\nüö® CRITICAL: {identical_count} problem(s) with identical code failed!\")\n",
    "        print(f\"   This suggests imports are causing HARM somehow.\")\n",
    "        print(f\"   Possible causes:\")\n",
    "        print(f\"     - Namespace conflicts (pre-loaded import shadows something)\")\n",
    "        print(f\"     - Execution timeout (imports slow down execution?)\")\n",
    "        print(f\"     - Evaluation bug in our test setup\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ All 'NOW FAILS' are due to DIFFERENT code\")\n",
    "        print(f\"   This is normal temperature variation - NOT caused by imports\")\n",
    "        print(f\"   Imports are NOT causing harm!\")\n",
    "else:\n",
    "    print(\"\\nNo comparison data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Generated Code (First 5 Problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE GENERATED CODE (First 5)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx, row in df_test.head(5).iterrows():\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"Task ID: {row['task_id']}\")\n",
    "    print(f\"Test Passed: {'‚úÖ YES' if row['test_passed'] else '‚ùå NO'}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(\"\\nGenerated Code:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(row['generated_code'])\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inspect Changed Problems (If Any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'changed_tasks' in locals() and len(changed_tasks) > 0:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DETAILED INSPECTION OF CHANGED PROBLEMS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for task_id in changed_tasks:\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Task ID: {task_id}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Get test version\n",
    "        test_row = df_test[df_test['task_id'] == task_id].iloc[0]\n",
    "        baseline_row = df_baseline[df_baseline['task_id'] == task_id].iloc[0]\n",
    "        \n",
    "        print(f\"\\nüìä Status:\")\n",
    "        print(f\"  Baseline (no imports): {'PASS' if baseline_row['test_passed'] else 'FAIL'}\")\n",
    "        print(f\"  Test (with imports):   {'PASS' if test_row['test_passed'] else 'FAIL'}\")\n",
    "        \n",
    "        print(f\"\\nüìù Baseline Code:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(baseline_row['generated_code'])\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        print(f\"\\nüìù Test Code (with imports):\")\n",
    "        print(\"-\" * 80)\n",
    "        print(test_row['generated_code'])\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Check if codes are identical\n",
    "        if test_row['generated_code'] == baseline_row['generated_code']:\n",
    "            print(f\"\\nüí° Code is IDENTICAL - imports helped evaluation, not generation\")\n",
    "        else:\n",
    "            print(f\"\\nüí° Code is DIFFERENT - model generated different solution\")\n",
    "else:\n",
    "    print(\"No changed problems to inspect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Check for Import Statements in Generated Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LIBRARY USAGE ANALYSIS (Corrected)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Count how many generated codes actually USE libraries (not import statements!)\n",
    "import re\n",
    "\n",
    "def detect_library_usage(code):\n",
    "    \"\"\"\n",
    "    Check if code USES library functions (not if it imports them).\n",
    "    \n",
    "    Examples:\n",
    "    - math.sqrt() ‚Üí Uses math\n",
    "    - re.sub() ‚Üí Uses re\n",
    "    - Counter() ‚Üí Uses collections.Counter\n",
    "    - reduce() ‚Üí Uses functools.reduce\n",
    "    \"\"\"\n",
    "    if pd.isna(code):\n",
    "        return {}\n",
    "    \n",
    "    code_str = str(code)\n",
    "    usage = {}\n",
    "    \n",
    "    # Check for module.function() patterns\n",
    "    patterns = {\n",
    "        'math': r'\\bmath\\.(\\w+)',\n",
    "        're': r'\\bre\\.(\\w+)',\n",
    "        'collections': r'\\bcollections\\.(\\w+)',\n",
    "        'itertools': r'\\bitertools\\.(\\w+)',\n",
    "        'functools': r'\\bfunctools\\.(\\w+)',\n",
    "        'random': r'\\brandom\\.(\\w+)',\n",
    "        'string': r'\\bstring\\.(\\w+)',\n",
    "        'heapq': r'\\bheapq\\.(\\w+)',\n",
    "        'bisect': r'\\bbisect\\.(\\w+)',\n",
    "        'operator': r'\\boperator\\.(\\w+)',\n",
    "    }\n",
    "    \n",
    "    for lib, pattern in patterns.items():\n",
    "        if re.search(pattern, code_str):\n",
    "            usage[lib] = True\n",
    "    \n",
    "    # Check for bare function calls (without module prefix)\n",
    "    # These assume the function was imported: \"from collections import Counter\"\n",
    "    bare_functions = {\n",
    "        'collections': [r'\\bCounter\\(', r'\\bdefaultdict\\(', r'\\bdeque\\(', r'\\bnamedtuple\\('],\n",
    "        'itertools': [r'\\bcombinations\\(', r'\\bpermutations\\(', r'\\bchain\\(', r'\\bcompress\\('],\n",
    "        'functools': [r'\\breduce\\(', r'\\blru_cache'],\n",
    "        'random': [r'\\brandint\\(', r'\\brandrange\\(', r'\\bchoice\\('],\n",
    "        'string': [r'\\bascii_lowercase\\b', r'\\bascii_uppercase\\b', r'\\bdigits\\b'],\n",
    "        'heapq': [r'\\bheappush\\(', r'\\bheappop\\(', r'\\bheapify\\('],\n",
    "        'bisect': [r'\\bbisect_left\\(', r'\\bbisect_right\\('],\n",
    "    }\n",
    "    \n",
    "    for lib, funcs in bare_functions.items():\n",
    "        for func_pattern in funcs:\n",
    "            if re.search(func_pattern, code_str):\n",
    "                usage[lib] = True\n",
    "                break\n",
    "    \n",
    "    return usage\n",
    "\n",
    "# Apply to dataframe\n",
    "df_test['library_usage'] = df_test['generated_code'].apply(detect_library_usage)\n",
    "df_test['uses_libraries'] = df_test['library_usage'].apply(lambda x: len(x) > 0)\n",
    "\n",
    "n_with_libs = df_test['uses_libraries'].sum()\n",
    "n_without_libs = len(df_test) - n_with_libs\n",
    "\n",
    "print(f\"\\nüìä Library Usage Statistics (CORRECTED):\")\n",
    "print(f\"  Codes USING libraries: {n_with_libs}/{len(df_test)} ({n_with_libs/len(df_test)*100:.1f}%)\")\n",
    "print(f\"  Codes WITHOUT libraries: {n_without_libs}/{len(df_test)} ({n_without_libs/len(df_test)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüí° Key Insight:\")\n",
    "if n_with_libs > len(df_test) * 0.7:\n",
    "    print(f\"  Most codes ({n_with_libs/len(df_test)*100:.1f}%) USE libraries\")\n",
    "    print(f\"  ‚Üí Pre-loading imports SHOULD help significantly\")\n",
    "elif n_with_libs < len(df_test) * 0.2:\n",
    "    print(f\"  Most codes ({n_without_libs/len(df_test)*100:.1f}%) are pure Python\")\n",
    "    print(f\"  ‚Üí Pre-loading imports won't help much (and it didn't!)\")\n",
    "else:\n",
    "    print(f\"  Some codes ({n_with_libs/len(df_test)*100:.1f}%) use libraries\")\n",
    "    print(f\"  ‚Üí Pre-loading should help those cases\")\n",
    "\n",
    "# Count which libraries are most used\n",
    "from collections import Counter as PyCounter\n",
    "all_libs = []\n",
    "for usage in df_test['library_usage']:\n",
    "    all_libs.extend(usage.keys())\n",
    "lib_counts = PyCounter(all_libs)\n",
    "\n",
    "print(f\"\\nüìö Most Used Libraries:\")\n",
    "for lib, count in lib_counts.most_common(10):\n",
    "    print(f\"  {lib:15s}: {count:4d} codes ({count/len(df_test)*100:.1f}%)\")\n",
    "\n",
    "# Pass rate by library usage\n",
    "with_libs = df_test[df_test['uses_libraries']]\n",
    "without_libs = df_test[~df_test['uses_libraries']]\n",
    "\n",
    "pass_rate_with = with_libs['test_passed'].mean() * 100 if len(with_libs) > 0 else 0\n",
    "pass_rate_without = without_libs['test_passed'].mean() * 100 if len(without_libs) > 0 else 0\n",
    "\n",
    "print(f\"\\nüìà Pass Rates:\")\n",
    "print(f\"  Codes WITH libraries: {pass_rate_with:.1f}% ({with_libs['test_passed'].sum()}/{len(with_libs)} passed)\")\n",
    "print(f\"  Codes WITHOUT libraries: {pass_rate_without:.1f}% ({without_libs['test_passed'].sum()}/{len(without_libs)} passed)\")\n",
    "\n",
    "# Sample codes with library usage\n",
    "print(f\"\\nüìù Sample codes USING libraries (showing library calls):\")\n",
    "with_lib_samples = df_test[df_test['uses_libraries']].head(5)\n",
    "for idx, row in with_lib_samples.iterrows():\n",
    "    print(f\"\\n  Task {row['task_id']} ({'PASS' if row['test_passed'] else 'FAIL'}): Uses {list(row['library_usage'].keys())}\")\n",
    "    print(\"  \" + \"-\" * 76)\n",
    "    code_lines = row['generated_code'].split('\\n')[:5]\n",
    "    for line in code_lines:\n",
    "        print(f\"  {line}\")\n",
    "    if len(row['generated_code'].split('\\n')) > 5:\n",
    "        print(\"  ...\")\n",
    "\n",
    "print(f\"\\nüìù Sample codes WITHOUT library usage (pure Python):\")\n",
    "without_lib_samples = df_test[~df_test['uses_libraries']].head(3)\n",
    "for idx, row in without_lib_samples.iterrows():\n",
    "    print(f\"\\n  Task {row['task_id']} ({'PASS' if row['test_passed'] else 'FAIL'}):\")\n",
    "    print(\"  \" + \"-\" * 76)\n",
    "    code_lines = row['generated_code'].split('\\n')[:3]\n",
    "    for line in code_lines:\n",
    "        print(f\"  {line}\")\n",
    "    if len(row['generated_code'].split('\\n')) > 3:\n",
    "        print(\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Full Dataset View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FULL TEST DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nShowing all {len(df_test)} records:\")\n",
    "\n",
    "# Temporarily set max_rows to None to show ALL records\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_test[['task_id', 'test_passed', 'generated_code', 'generation_time', 'uses_libraries', 'library_usage']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"INVESTIGATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"  Baseline pass rate: {baseline_rate:.2f}%\")\n",
    "print(f\"  Test pass rate: {test_rate:.2f}%\")\n",
    "print(f\"  Difference: {diff_rate:+.2f}% ({diff_passed:+d} problems)\")\n",
    "\n",
    "print(f\"\\nüîç Analysis:\")\n",
    "print(f\"  Problems changed: {len(changed_tasks) if 'changed_tasks' in locals() else 'Unknown'}\")\n",
    "print(f\"  Codes using libraries: {n_with_libs}/{len(df_test)} ({n_with_libs/len(df_test)*100:.1f}%)\")\n",
    "print(f\"  Imports pre-loaded: {len(metadata['imports'])}\")\n",
    "\n",
    "print(f\"\\nüí° Conclusion:\")\n",
    "if abs(diff_passed) <= 2:\n",
    "    print(f\"  ‚ö†Ô∏è  Pre-loading 55 standard library imports has NEGLIGIBLE impact\")\n",
    "    print(f\"  Possible reasons:\")\n",
    "    print(f\"    1. Most codes ({n_without_libs/len(df_test)*100:.1f}%) are pure Python - don't use libraries\")\n",
    "    print(f\"    2. Only {n_with_libs} codes ({n_with_libs/len(df_test)*100:.1f}%) actually USE libraries\")\n",
    "    print(f\"    3. Of those, most fail for OTHER reasons (logic errors), not imports\")\n",
    "    print(f\"    4. Temperature 0.0 produces simple, self-contained solutions\")\n",
    "    print(f\"\\n  üìå Recommendation: NOT worth re-running full pipeline\")\n",
    "    print(f\"  üìå Actual library usage is {n_with_libs/len(df_test)*100:.1f}% - too low to matter!\")\n",
    "else:\n",
    "    print(f\"  ‚úÖ Pre-loading imports shows measurable improvement\")\n",
    "    print(f\"  üìå Recommendation: Consider re-running pipeline\")\n",
    "\n",
    "print(\"\\nüéâ Inspection complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pva_sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}