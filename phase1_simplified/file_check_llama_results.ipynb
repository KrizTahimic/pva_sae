{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Phase 1: LLAMA + MBPP Dataset Results Inspection\n",
    "\n",
    "This notebook inspects Phase 1 LLAMA results to verify:\n",
    "- Dataset files created correctly\n",
    "- Model used (LLAMA-3.1-8B)\n",
    "- Prompts formatted correctly\n",
    "- Code generation working\n",
    "- Evaluation results (pass/fail)\n",
    "- Activations captured (31 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Set pandas display options to show FULL content\n",
    "pd.set_option('display.max_colwidth', None)  # Show full column content (NO LIMITS)\n",
    "pd.set_option('display.max_columns', None)   # Show all columns\n",
    "pd.set_option('display.width', None)         # Don't wrap to multiple lines\n",
    "pd.set_option('display.max_rows', None)      # Show ALL rows (no limit)\n",
    "\n",
    "print(\"âœ… Pandas display options set to show FULL content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-discovery of Phase 1 LLAMA data\n",
    "datasets_dir = \"../data/phase1_0_llama/\"\n",
    "pattern = os.path.join(datasets_dir, \"dataset_*.parquet\")\n",
    "matching_files = glob.glob(pattern)\n",
    "\n",
    "if matching_files:\n",
    "    # Sort by timestamp (filename)\n",
    "    matching_files.sort(reverse=True)  # Most recent first\n",
    "    print(\"=\" * 80)\n",
    "    print(\"PHASE 1: LLAMA + MBPP DATASET GENERATION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nğŸ” Found {len(matching_files)} dataset file(s)\")\n",
    "    for file in matching_files:\n",
    "        file_size = os.path.getsize(file) / 1024  # KB\n",
    "        print(f\"  ğŸ“ {Path(file).name} ({file_size:.2f} KB)\")\n",
    "    \n",
    "    # Use most recent file\n",
    "    latest_file = matching_files[0]\n",
    "    print(f\"\\nğŸ“„ Using most recent: {Path(latest_file).name}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"âŒ No dataset files found in {datasets_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check activations directory\n",
    "activations_dir = Path(datasets_dir) / \"activations\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ACTIVATIONS DIRECTORY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if activations_dir.exists():\n",
    "    print(f\"\\nâœ… Activations directory exists: {activations_dir}\")\n",
    "    \n",
    "    # Check subdirectories\n",
    "    subdirs = [d for d in activations_dir.iterdir() if d.is_dir()]\n",
    "    print(f\"\\nğŸ“ Subdirectories ({len(subdirs)}):\")\n",
    "    for subdir in subdirs:\n",
    "        files = list(subdir.glob(\"*.npz\"))\n",
    "        print(f\"  - {subdir.name}/: {len(files)} activation files\")\n",
    "        if files:\n",
    "            print(f\"    Sample: {files[0].name}\")\n",
    "            \n",
    "            # Check activation dimensions for LLAMA (should be 4096)\n",
    "            sample_data = np.load(files[0])\n",
    "            for key in sample_data.files:\n",
    "                print(f\"    Shape ({key}): {sample_data[key].shape}\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Activations directory not found: {activations_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display dataset\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"DATASET CONTENTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df = pd.read_parquet(latest_file)\n",
    "\n",
    "# Basic stats\n",
    "print(f\"\\nğŸ“Š Statistics:\")\n",
    "print(f\"  - Total records: {len(df)}\")\n",
    "print(f\"  - Columns: {list(df.columns)}\")\n",
    "\n",
    "# Pass rate\n",
    "if 'test_passed' in df.columns:\n",
    "    n_passed = df['test_passed'].sum()\n",
    "    pass_rate = n_passed / len(df) * 100\n",
    "    print(f\"\\nâœ… Pass Rate:\")\n",
    "    print(f\"  - Passed: {n_passed}/{len(df)} ({pass_rate:.2f}%)\")\n",
    "    print(f\"  - Failed: {len(df) - n_passed}/{len(df)} ({100 - pass_rate:.2f}%)\")\n",
    "\n",
    "# Generation time stats\n",
    "if 'generation_time' in df.columns:\n",
    "    print(f\"\\nâ±ï¸  Generation Time:\")\n",
    "    print(f\"  - Mean: {df['generation_time'].mean():.2f}s\")\n",
    "    print(f\"  - Median: {df['generation_time'].median():.2f}s\")\n",
    "    print(f\"  - Min: {df['generation_time'].min():.2f}s\")\n",
    "    print(f\"  - Max: {df['generation_time'].max():.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all records\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"ALL RECORDS:\")\n",
    "print(\"=\" * 80)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample correct and incorrect generations\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE CORRECT GENERATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'test_passed' in df.columns and df['test_passed'].any():\n",
    "    correct_sample = df[df['test_passed'] == True].iloc[0]\n",
    "    print(f\"\\nğŸ“‹ Task ID: {correct_sample.get('task_id', 'N/A')}\")\n",
    "    print(f\"\\nğŸ“ Prompt:\")\n",
    "    print(correct_sample.get('prompt', 'N/A')[:500] + \"...\" if len(str(correct_sample.get('prompt', ''))) > 500 else correct_sample.get('prompt', 'N/A'))\n",
    "    print(f\"\\nğŸ’» Generated Code:\")\n",
    "    print(correct_sample.get('generated_code', 'N/A'))\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No correct generations found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample incorrect generation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE INCORRECT GENERATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'test_passed' in df.columns and (~df['test_passed']).any():\n",
    "    incorrect_sample = df[df['test_passed'] == False].iloc[0]\n",
    "    print(f\"\\nğŸ“‹ Task ID: {incorrect_sample.get('task_id', 'N/A')}\")\n",
    "    print(f\"\\nğŸ“ Prompt:\")\n",
    "    print(incorrect_sample.get('prompt', 'N/A')[:500] + \"...\" if len(str(incorrect_sample.get('prompt', ''))) > 500 else incorrect_sample.get('prompt', 'N/A'))\n",
    "    print(f\"\\nğŸ’» Generated Code:\")\n",
    "    print(incorrect_sample.get('generated_code', 'N/A'))\n",
    "    if 'error_message' in incorrect_sample and incorrect_sample['error_message']:\n",
    "        print(f\"\\nâŒ Error:\")\n",
    "        print(incorrect_sample['error_message'])\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No incorrect generations found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OVERALL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset file: {Path(latest_file).name}\")\n",
    "print(f\"ğŸ“Š Total records: {len(df)}\")\n",
    "if 'test_passed' in df.columns:\n",
    "    print(f\"âœ… Pass rate: {df['test_passed'].sum()}/{len(df)} ({df['test_passed'].mean()*100:.2f}%)\")\n",
    "print(f\"ğŸ“ Activations exist: {'âœ…' if activations_dir.exists() else 'âŒ'}\")\n",
    "\n",
    "# Check if activations have correct dimension for LLAMA (4096)\n",
    "if activations_dir.exists():\n",
    "    task_acts_dir = activations_dir / \"task_activations\"\n",
    "    if task_acts_dir.exists():\n",
    "        sample_files = list(task_acts_dir.glob(\"*.npz\"))[:1]\n",
    "        if sample_files:\n",
    "            data = np.load(sample_files[0])\n",
    "            for key in data.files:\n",
    "                dim = data[key].shape[-1]\n",
    "                expected = 4096  # LLAMA hidden size\n",
    "                status = 'âœ…' if dim == expected else 'âŒ'\n",
    "                print(f\"{status} Activation dimension: {dim} (expected {expected} for LLAMA)\")\n",
    "\n",
    "print(\"\\nğŸ‰ Phase 1 LLAMA results inspection complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
