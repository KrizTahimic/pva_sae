{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "n2u2n5p6d3",
   "metadata": {},
   "source": [
    "# Phase 1 Dataset Checker\n",
    "\n",
    "This notebook checks the latest Phase 1 parquet file output and displays:\n",
    "- The first 10 rows of data (as requested)\n",
    "- Dataset statistics (pass/fail rates)\n",
    "- Sample correct and incorrect code solutions\n",
    "- Activation file counts\n",
    "- Data types and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cad85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for parquet files in: /Users/krizroycetahimic/Documents/Thesis/Code/pva_sae/phase1_simplified/../data/phase1_0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# Find the data directory\n",
    "data_dir = Path(\"../data/phase1_0\")\n",
    "print(f\"Looking for parquet files in: {data_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8zscdlk8k4i",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 parquet files:\n",
      "1. dataset_sae_20250629_161228.parquet (modified: 2025-06-29 16:12:28)\n",
      "2. dataset_sae_20250629_154004.parquet (modified: 2025-06-29 15:40:04)\n",
      "3. dataset_sae_20250629_152134.parquet (modified: 2025-06-29 15:21:34)\n",
      "4. dataset_sae_20250629_151007.parquet (modified: 2025-06-29 15:10:07)\n",
      "5. dataset_sae_20250629_150145.parquet (modified: 2025-06-29 15:01:45)\n",
      "\n",
      "Using latest file: dataset_sae_20250629_161228.parquet\n"
     ]
    }
   ],
   "source": [
    "# Find all parquet files\n",
    "parquet_files = list(data_dir.glob(\"*.parquet\"))\n",
    "parquet_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "\n",
    "if not parquet_files:\n",
    "    print(\"No parquet files found!\")\n",
    "else:\n",
    "    print(f\"Found {len(parquet_files)} parquet files:\")\n",
    "    for i, file in enumerate(parquet_files[:5]):  # Show top 5 most recent\n",
    "        mtime = datetime.fromtimestamp(file.stat().st_mtime)\n",
    "        print(f\"{i+1}. {file.name} (modified: {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "    \n",
    "    # Use the most recent file\n",
    "    latest_file = parquet_files[0]\n",
    "    print(f\"\\nUsing latest file: {latest_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3rn6g0ignfp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3, 7)\n",
      "Columns: ['task_id', 'text', 'code', 'test_list', 'cyclomatic_complexity', 'generated_code', 'test_passed']\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>text</th>\n",
       "      <th>code</th>\n",
       "      <th>test_list</th>\n",
       "      <th>cyclomatic_complexity</th>\n",
       "      <th>generated_code</th>\n",
       "      <th>test_passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Write a function to find the similar elements ...</td>\n",
       "      <td>def similar_elements(test_tup1, test_tup2):\\r\\...</td>\n",
       "      <td>[assert similar_elements((3, 4, 5, 6),(5, 7, 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>def similar_elements(list1, list2):\\n    # You...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Write a python function to identify non-prime ...</td>\n",
       "      <td>import math\\r\\ndef is_not_prime(n):\\r\\n    res...</td>\n",
       "      <td>[assert is_not_prime(2) == False, assert is_no...</td>\n",
       "      <td>3</td>\n",
       "      <td>def is_not_prime(n):\\n    if n == 1:\\n        ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Write a function to find the largest integers ...</td>\n",
       "      <td>import heapq as hq\\r\\ndef heap_queue_largest(n...</td>\n",
       "      <td>[assert heap_queue_largest( [25, 35, 22, 85, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>def heap_queue_largest(numbers, k):\\n    # You...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                               text  \\\n",
       "0        2  Write a function to find the similar elements ...   \n",
       "1        3  Write a python function to identify non-prime ...   \n",
       "2        4  Write a function to find the largest integers ...   \n",
       "\n",
       "                                                code  \\\n",
       "0  def similar_elements(test_tup1, test_tup2):\\r\\...   \n",
       "1  import math\\r\\ndef is_not_prime(n):\\r\\n    res...   \n",
       "2  import heapq as hq\\r\\ndef heap_queue_largest(n...   \n",
       "\n",
       "                                           test_list  cyclomatic_complexity  \\\n",
       "0  [assert similar_elements((3, 4, 5, 6),(5, 7, 4...                      1   \n",
       "1  [assert is_not_prime(2) == False, assert is_no...                      3   \n",
       "2  [assert heap_queue_largest( [25, 35, 22, 85, 1...                      1   \n",
       "\n",
       "                                      generated_code  test_passed  \n",
       "0  def similar_elements(list1, list2):\\n    # You...        False  \n",
       "1  def is_not_prime(n):\\n    if n == 1:\\n        ...         True  \n",
       "2  def heap_queue_largest(numbers, k):\\n    # You...        False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the latest parquet file\n",
    "df = pd.read_parquet(latest_file)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9q8bw7pgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "if 'test_passed' in df.columns:\n",
    "    n_correct = df['test_passed'].sum()\n",
    "    n_incorrect = (~df['test_passed']).sum()\n",
    "    n_total = len(df)\n",
    "    pass_rate = n_correct/n_total*100 if n_total > 0 else 0\n",
    "    \n",
    "    print(\"=== Dataset Statistics ===\")\n",
    "    print(f\"Total tasks: {n_total}\")\n",
    "    print(f\"Correct solutions: {n_correct} ({pass_rate:.1f}%)\")\n",
    "    print(f\"Incorrect solutions: {n_incorrect} ({100-pass_rate:.1f}%)\")\n",
    "else:\n",
    "    print(\"No 'test_passed' column found in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r7fcojtjnwk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of correct and incorrect solutions\n",
    "if 'test_passed' in df.columns and 'generated_code' in df.columns:\n",
    "    print(\"=== Sample Correct Solution ===\")\n",
    "    correct_sample = df[df['test_passed'] == True].iloc[0] if any(df['test_passed']) else None\n",
    "    if correct_sample is not None:\n",
    "        print(f\"Task ID: {correct_sample['task_id']}\")\n",
    "        print(f\"Problem: {correct_sample['text'][:200]}...\" if len(correct_sample['text']) > 200 else correct_sample['text'])\n",
    "        print(f\"\\nGenerated Code:\\n{correct_sample['generated_code']}\")\n",
    "    \n",
    "    print(\"\\n=== Sample Incorrect Solution ===\")\n",
    "    incorrect_sample = df[df['test_passed'] == False].iloc[0] if any(~df['test_passed']) else None\n",
    "    if incorrect_sample is not None:\n",
    "        print(f\"Task ID: {incorrect_sample['task_id']}\")\n",
    "        print(f\"Problem: {incorrect_sample['text'][:200]}...\" if len(incorrect_sample['text']) > 200 else incorrect_sample['text'])\n",
    "        print(f\"\\nGenerated Code:\\n{incorrect_sample['generated_code']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oy28279gox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check activation files\n",
    "activation_dir = data_dir / \"activations\"\n",
    "if activation_dir.exists():\n",
    "    correct_activations = list((activation_dir / \"correct\").glob(\"*.npz\"))\n",
    "    incorrect_activations = list((activation_dir / \"incorrect\").glob(\"*.npz\"))\n",
    "    \n",
    "    print(\"=== Activation Files ===\")\n",
    "    print(f\"Correct activations: {len(correct_activations)} files\")\n",
    "    print(f\"Incorrect activations: {len(incorrect_activations)} files\")\n",
    "    \n",
    "    # Show sample of activation filenames\n",
    "    if correct_activations:\n",
    "        print(\"\\nSample correct activation files:\")\n",
    "        for file in correct_activations[:5]:\n",
    "            print(f\"  - {file.name}\")\n",
    "else:\n",
    "    print(\"No activations directory found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ttv41c1e18i",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"=== Column Data Types ===\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n=== Missing Values ===\")\n",
    "print(df.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pva_sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
