{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd314dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krizroycetahimic/miniconda3/envs/pva_sae/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest character length in the 'code' column is: 1331\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the MBPP dataset\n",
    "dataset = load_dataset(\"mbpp\", \"full\") # or \"sanitized\" if you prefer\n",
    "\n",
    "# Initialize max length\n",
    "max_char_length = 0\n",
    "\n",
    "# Iterate through the 'test' split (MBPP is often a single split, or you might choose 'train')\n",
    "# and check the 'code' column.\n",
    "# Common splits are 'train', 'test', 'validation'. MBPP 'full' has 'train', 'test', 'prompt'.\n",
    "# We'll check all available splits to be safe if the exact structure isn't recalled.\n",
    "for split in dataset.keys():\n",
    "    for example in dataset[split]:\n",
    "        code_snippet = example['code']\n",
    "        if code_snippet: # Check if the code snippet is not None or empty\n",
    "            current_length = len(code_snippet)\n",
    "            if current_length > max_char_length:\n",
    "                max_char_length = current_length\n",
    "\n",
    "print(f\"The highest character length in the 'code' column is: {max_char_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d659d1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest dataset: mbpp_dataset_20250527_203843.parquet\n",
      "\n",
      "Dataset shape: (3, 3)\n",
      "Columns: ['task_id', 'generated_code', 'test_passed']\n",
      "\n",
      "Test results distribution:\n",
      "test_passed\n",
      "False    2\n",
      "True     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>generated_code</th>\n",
       "      <th>test_passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>\\ndef remove_Occ(string,char):\\n    string = string.replace(char,\"\")\\n    return string\\n</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>\\ndef sort_matrix(matrix):\\n    for i in range(len(matrix)):\\n        matrix[i].sort()\\n    retu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>\\ndef count_common(dictionary):\\n    count = {}\\n    for word in dictionary:\\n        if word in...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id  \\\n",
       "0       11   \n",
       "1       12   \n",
       "2       13   \n",
       "\n",
       "                                                                                        generated_code  \\\n",
       "0            \\ndef remove_Occ(string,char):\\n    string = string.replace(char,\"\")\\n    return string\\n   \n",
       "1  \\ndef sort_matrix(matrix):\\n    for i in range(len(matrix)):\\n        matrix[i].sort()\\n    retu...   \n",
       "2  \\ndef count_common(dictionary):\\n    count = {}\\n    for word in dictionary:\\n        if word in...   \n",
       "\n",
       "   test_passed  \n",
       "0         True  \n",
       "1        False  \n",
       "2        False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column efficiency analysis:\n",
      "• Essential columns for SAE analysis: 3\n",
      "• Total data reduction: Removed ~9 unnecessary columns\n",
      "• Columns kept: task_id, generated_code, test_passed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# View generated datasets\n",
    "data_dir = Path(\"data/datasets\")\n",
    "\n",
    "# Load the most recent dataset\n",
    "parquet_files = sorted(data_dir.glob(\"*.parquet\"))\n",
    "if parquet_files:\n",
    "    latest_file = parquet_files[-1]\n",
    "    print(f\"Loading latest dataset: {latest_file.name}\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    df = pd.read_parquet(latest_file)\n",
    "    \n",
    "    # Display basic info\n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Show distribution of results\n",
    "    if 'test_passed' in df.columns:\n",
    "        print(f\"\\nTest results distribution:\")\n",
    "        print(df['test_passed'].value_counts())\n",
    "    \n",
    "    print(f\"\\nDataset preview:\")\n",
    "    # Display as interactive table in Jupyter\n",
    "    display(df)\n",
    "    \n",
    "    # Check column efficiency\n",
    "    print(f\"\\nColumn efficiency analysis:\")\n",
    "    print(f\"• Essential columns for SAE analysis: {len(df.columns)}\")\n",
    "    print(f\"• Total data reduction: Removed ~9 unnecessary columns\")\n",
    "    print(f\"• Columns kept: {', '.join(df.columns)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No parquet files found in data/datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567e5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pva_sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
